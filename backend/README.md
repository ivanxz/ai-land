# LangChain LLM API

åŸºäºFastAPIå’ŒLangChainæ„å»ºçš„ç®€å•LLMåº”ç”¨ï¼Œæ”¯æŒAPIè®¿é—®å’ŒSSEï¼ˆServer-Sent Eventsï¼‰æµå¼è¾“å‡ºã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸš€ åŸºäºFastAPIçš„é«˜æ€§èƒ½å¼‚æ­¥API
- ğŸ¤– é›†æˆLangChainå’ŒOpenAI GPTæ¨¡å‹
- ğŸ“¡ æ”¯æŒSSEæµå¼è¾“å‡º
- ğŸ”§ å¯é…ç½®çš„æ¨¡å‹å‚æ•°ï¼ˆtemperatureã€max_tokensç­‰ï¼‰
- ğŸŒ CORSæ”¯æŒï¼Œä¾¿äºå‰ç«¯é›†æˆ
- ğŸ“ å®Œæ•´çš„APIæ–‡æ¡£ï¼ˆSwagger UIï¼‰

## å®‰è£…ä¾èµ–

```bash
# å®‰è£…é¡¹ç›®ä¾èµ–
uv sync
```

## ç¯å¢ƒé…ç½®

åˆ›å»º `.env` æ–‡ä»¶å¹¶è®¾ç½®OpenAI APIå¯†é’¥ï¼š

```bash
OPENAI_API_KEY=your_openai_api_key_here
```

## å¯åŠ¨æœåŠ¡

```bash
# æ–¹å¼1ï¼šç›´æ¥è¿è¡Œ
python -m app.main

# æ–¹å¼2ï¼šä½¿ç”¨uvicorn
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

æœåŠ¡å¯åŠ¨åï¼Œè®¿é—® http://localhost:8000 æŸ¥çœ‹APIçŠ¶æ€ã€‚

## APIæ¥å£

### 1. å¥åº·æ£€æŸ¥
```
GET /api/health
```

### 2. æ™®é€šèŠå¤©æ¥å£
```
POST /api/chat
```

è¯·æ±‚ä½“ï¼š
```json
{
    "message": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±",
    "system_prompt": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹",
    "temperature": 0.7,
    "max_tokens": 1000
}
```

### 3. SSEæµå¼èŠå¤©æ¥å£
```
POST /api/chat/stream
```

è¿”å›Server-Sent Eventsæ ¼å¼çš„æµå¼æ•°æ®ï¼š
```
data: {"type": "token", "content": "ä½ å¥½"}
data: {"type": "token", "content": "ï¼"}
data: {"type": "end", "content": ""}
```

## APIæ–‡æ¡£

å¯åŠ¨æœåŠ¡åï¼Œè®¿é—®ä»¥ä¸‹åœ°å€æŸ¥çœ‹è‡ªåŠ¨ç”Ÿæˆçš„APIæ–‡æ¡£ï¼š

- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc
